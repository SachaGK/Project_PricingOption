{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-0",
   "source": [
    "# Notebook 03: Model Training and Evaluation\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook trains and evaluates machine learning models to predict Apple call option prices.\n",
    "\n",
    "**Objectives:**\n",
    "- Load clean ML-ready dataset\n",
    "- Perform dimensionality reduction analysis (PCA)\n",
    "- Split data into train/validation/test sets (stratified by maturity)\n",
    "- Train baseline and advanced models with hyperparameter tuning\n",
    "- Evaluate performance with multiple metrics\n",
    "- Analyze errors and model behavior\n",
    "- Save best model for future use\n",
    "\n",
    "**Models tested:**\n",
    "1. Linear Regression (baseline)\n",
    "2. Random Forest (with Grid Search)\n",
    "3. XGBoost (with Grid Search)\n",
    "\n",
    "**Target:** Predict C_LAST (call option price)\n",
    "\n",
    "**References:**\n",
    "- Chen & Guestrin (2016): XGBoost - A Scalable Tree Boosting System\n",
    "- Breiman (2001): Random Forests\n",
    "- Hutchinson et al. (1994): Nonparametric Option Pricing via Learning Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-1",
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-2",
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport pickle\nimport json\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import (\n    train_test_split, \n    cross_val_score, \n    GridSearchCV,\n    learning_curve\n)\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom xgboost import XGBRegressor\n\npd.set_option(\"display.max_columns\", 100)\npd.set_option(\"display.width\", 120)\nplt.style.use('seaborn-v0_8-whitegrid')\n\nPROJECT_ROOT = Path(\"..\").resolve()\nDATA_PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\nFIGS_DIR = PROJECT_ROOT / \"figs\"\nMODELS_DIR = PROJECT_ROOT / \"models\"\n\nFIGS_DIR.mkdir(parents=True, exist_ok=True)\nMODELS_DIR.mkdir(parents=True, exist_ok=True)\n\nML_DATA_FILE = DATA_PROCESSED_DIR / \"AAPL_ML_READY.csv\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-3",
   "outputs": [],
   "source": "df = pd.read_csv(ML_DATA_FILE)\nprint(f\"Dataset loaded: {df.shape[0]:,} rows x {df.shape[1]} columns\")\ndf.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-4",
   "outputs": [],
   "source": "print(f\"Missing values: {df.isna().sum().sum()}\")\nprint(f\"Duplicates: {df.duplicated().sum()}\")\nprint(f\"Target range: [{df['C_LAST'].min():.2f}, {df['C_LAST'].max():.2f}] USD\")\ndf.describe()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-5",
   "source": [
    "## 2. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-6",
   "outputs": [],
   "source": "numeric_cols = ['UNDERLYING_LAST', 'STRIKE', 'DTE', 'LOG_DTE', 'LOG_MONEYNESS', 'C_IV', 'C_LAST']\ncorr_matrix = df[numeric_cols].corr()\n\nplt.figure(figsize=(10, 8))\nmask = np.triu(np.ones_like(corr_matrix, dtype=bool))\nsns.heatmap(\n    corr_matrix, \n    annot=True, \n    fmt='.2f', \n    cmap='RdBu_r', \n    center=0,\n    mask=mask,\n    square=True,\n    linewidths=0.5,\n    cbar_kws={'label': 'Correlation Coefficient'}\n)\nplt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.savefig(FIGS_DIR / \"correlation_heatmap.png\", dpi=120, bbox_inches='tight')\nplt.show()\n\nprint(\"\\nCorrelation with target (C_LAST):\")\nprint(corr_matrix['C_LAST'].sort_values(ascending=False))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-7",
   "source": [
    "## 3. Dimensionality Reduction Analysis (PCA)\n",
    "\n",
    "We perform PCA to understand the variance structure of our features.\n",
    "This helps identify if dimensionality reduction could improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-8",
   "outputs": [],
   "source": "feature_cols = ['UNDERLYING_LAST', 'STRIKE', 'DTE', 'LOG_DTE', 'LOG_MONEYNESS', 'C_IV']\nX_pca = df[feature_cols].copy()\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_pca)\n\npca = PCA()\npca.fit(X_scaled)\n\nexplained_variance = pca.explained_variance_ratio_\ncumulative_variance = np.cumsum(explained_variance)\n\nprint(\"PCA Explained Variance:\")\nfor i, (var, cum) in enumerate(zip(explained_variance, cumulative_variance)):\n    print(f\"  PC{i+1}: {var:.4f} ({var*100:.2f}%) | Cumulative: {cum:.4f} ({cum*100:.2f}%)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-9",
   "outputs": [],
   "source": "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\ncomponents = range(1, len(explained_variance) + 1)\naxes[0].bar(components, explained_variance, alpha=0.7, color='steelblue', label='Individual')\naxes[0].plot(components, cumulative_variance, 'ro-', label='Cumulative')\naxes[0].axhline(y=0.95, color='g', linestyle='--', label='95% threshold')\naxes[0].set_xlabel('Principal Component')\naxes[0].set_ylabel('Explained Variance Ratio')\naxes[0].set_title('PCA Scree Plot', fontweight='bold')\naxes[0].legend()\naxes[0].set_xticks(components)\naxes[0].grid(alpha=0.3)\n\nloadings = pd.DataFrame(\n    pca.components_[:2].T,\n    columns=['PC1', 'PC2'],\n    index=feature_cols\n)\nloadings.plot(kind='barh', ax=axes[1], color=['steelblue', 'coral'])\naxes[1].set_xlabel('Loading')\naxes[1].set_title('Feature Loadings (PC1 & PC2)', fontweight='bold')\naxes[1].axvline(x=0, color='black', linewidth=0.5)\naxes[1].grid(alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(FIGS_DIR / \"pca_analysis.png\", dpi=120)\nplt.show()\n\nn_components_95 = np.argmax(cumulative_variance >= 0.95) + 1\nprint(f\"\\nConclusion: {n_components_95} components needed to explain 95% of variance.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-10",
   "source": [
    "## 4. Train/Validation/Test Split\n",
    "\n",
    "We split the data into three sets:\n",
    "- **Train (70%):** Used to train models\n",
    "- **Validation (15%):** Used to tune hyperparameters\n",
    "- **Test (15%):** Used for final evaluation (never seen during training)\n",
    "\n",
    "**Important:** We use **stratified splitting** by maturity (DTE_BUCKET) to ensure all sets have similar distributions of short-term and long-term options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-11",
   "outputs": [],
   "source": "feature_cols = ['UNDERLYING_LAST', 'STRIKE', 'DTE', 'LOG_DTE', 'LOG_MONEYNESS', 'C_IV']\nX = df[feature_cols]\ny = df['C_LAST']\n\nX_train, X_temp, y_train, y_temp, bucket_train, bucket_temp = train_test_split(\n    X, y, df['DTE_BUCKET'],\n    test_size=0.30,\n    random_state=42,\n    stratify=df['DTE_BUCKET']\n)\n\nX_val, X_test, y_val, y_test = train_test_split(\n    X_temp, y_temp,\n    test_size=0.50,\n    random_state=42,\n    stratify=bucket_temp\n)\n\nprint(f\"Train size:      {X_train.shape[0]:,} ({X_train.shape[0]/len(X)*100:.1f}%)\")\nprint(f\"Validation size: {X_val.shape[0]:,} ({X_val.shape[0]/len(X)*100:.1f}%)\")\nprint(f\"Test size:       {X_test.shape[0]:,} ({X_test.shape[0]/len(X)*100:.1f}%)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-12",
   "source": [
    "## 5. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-13",
   "outputs": [],
   "source": "def evaluate_model(y_true, y_pred, dataset_name=\"\"):\n    mae = mean_absolute_error(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    r2 = r2_score(y_true, y_pred)\n    \n    print(f\"{dataset_name} Metrics:\")\n    print(f\"  MAE:  {mae:.2f} USD\")\n    print(f\"  RMSE: {rmse:.2f} USD\")\n    print(f\"  R²:   {r2:.4f}\")\n    \n    return {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n\n\ndef plot_learning_curve(estimator, X, y, title, cv=5, n_jobs=-1):\n    train_sizes, train_scores, val_scores = learning_curve(\n        estimator, X, y,\n        cv=cv,\n        n_jobs=n_jobs,\n        train_sizes=np.linspace(0.1, 1.0, 10),\n        scoring='neg_mean_absolute_error'\n    )\n    \n    train_scores_mean = -train_scores.mean(axis=1)\n    train_scores_std = train_scores.std(axis=1)\n    val_scores_mean = -val_scores.mean(axis=1)\n    val_scores_std = val_scores.std(axis=1)\n    \n    plt.figure(figsize=(10, 6))\n    plt.fill_between(train_sizes, \n                     train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, \n                     alpha=0.1, color='blue')\n    plt.fill_between(train_sizes, \n                     val_scores_mean - val_scores_std,\n                     val_scores_mean + val_scores_std, \n                     alpha=0.1, color='orange')\n    plt.plot(train_sizes, train_scores_mean, 'o-', color='blue', label='Training MAE')\n    plt.plot(train_sizes, val_scores_mean, 'o-', color='orange', label='Validation MAE')\n    \n    plt.xlabel('Training Set Size')\n    plt.ylabel('Mean Absolute Error (USD)')\n    plt.title(f'Learning Curve: {title}', fontweight='bold')\n    plt.legend(loc='best')\n    plt.grid(alpha=0.3)\n    \n    return train_sizes, train_scores_mean, val_scores_mean"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-14",
   "source": [
    "## 6. Model 1: Linear Regression (Baseline)\n",
    "\n",
    "We start with the simplest model to establish a baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-15",
   "outputs": [],
   "source": "print(\"Training Linear Regression...\")\nlr = LinearRegression()\nlr.fit(X_train, y_train)\n\ny_pred_lr_train = lr.predict(X_train)\ny_pred_lr_val = lr.predict(X_val)\ny_pred_lr_test = lr.predict(X_test)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"LINEAR REGRESSION RESULTS\")\nprint(\"=\"*60)\nlr_train_metrics = evaluate_model(y_train, y_pred_lr_train, \"Train\")\nprint()\nlr_val_metrics = evaluate_model(y_val, y_pred_lr_val, \"Validation\")\nprint()\nlr_test_metrics = evaluate_model(y_test, y_pred_lr_test, \"Test\")\n\nall_results = [{'Model': 'Linear Regression', **lr_test_metrics}]"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-16",
   "source": [
    "## 7. Model 2: Random Forest with Grid Search\n",
    "\n",
    "Random Forest can capture non-linear relationships and interactions between features.\n",
    "We use **Grid Search** to find the optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-17",
   "outputs": [],
   "source": "print(\"Running Grid Search for Random Forest...\")\n\nGRID_SEARCH_SAMPLE_SIZE = 100000\nnp.random.seed(42)\nsample_idx = np.random.choice(len(X_train), size=min(GRID_SEARCH_SAMPLE_SIZE, len(X_train)), replace=False)\nX_train_sample = X_train.iloc[sample_idx]\ny_train_sample = y_train.iloc[sample_idx]\nprint(f\"Grid Search using {len(X_train_sample):,} samples (from {len(X_train):,} total)\")\n\nrf_param_grid = {\n    'n_estimators': [100, 200],\n    'max_depth': [10, 20],\n    'min_samples_leaf': [5, 10]\n}\n\nrf_base = RandomForestRegressor(n_jobs=-1, random_state=42)\n\nrf_grid_search = GridSearchCV(\n    estimator=rf_base,\n    param_grid=rf_param_grid,\n    cv=3,\n    scoring='neg_mean_absolute_error',\n    n_jobs=-1,\n    verbose=1\n)\n\nrf_grid_search.fit(X_train_sample, y_train_sample)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"RANDOM FOREST GRID SEARCH RESULTS\")\nprint(\"=\"*60)\nprint(f\"Best parameters: {rf_grid_search.best_params_}\")\nprint(f\"Best CV MAE (on sample): {-rf_grid_search.best_score_:.2f} USD\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-18",
   "outputs": [],
   "source": "rf_best = rf_grid_search.best_estimator_\n\ny_pred_rf_train = rf_best.predict(X_train)\ny_pred_rf_val = rf_best.predict(X_val)\ny_pred_rf_test = rf_best.predict(X_test)\n\nprint(\"Random Forest Performance (Best Hyperparameters):\")\nprint(\"-\" * 50)\nrf_train_metrics = evaluate_model(y_train, y_pred_rf_train, \"Train\")\nprint()\nrf_val_metrics = evaluate_model(y_val, y_pred_rf_val, \"Validation\")\nprint()\nrf_test_metrics = evaluate_model(y_test, y_pred_rf_test, \"Test\")\n\nall_results.append({'Model': 'Random Forest', **rf_test_metrics})"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-19",
   "outputs": [],
   "source": "rf_cv_results = pd.DataFrame(rf_grid_search.cv_results_)\nrf_cv_results['MAE'] = -rf_cv_results['mean_test_score']\n\npivot_rf = rf_cv_results.pivot_table(\n    values='MAE',\n    index='param_max_depth',\n    columns='param_n_estimators',\n    aggfunc='mean'\n)\n\nplt.figure(figsize=(10, 6))\nsns.heatmap(pivot_rf, annot=True, fmt='.2f', cmap='YlOrRd_r', cbar_kws={'label': 'MAE (USD)'})\nplt.title('Random Forest Grid Search: MAE by Hyperparameters', fontweight='bold')\nplt.xlabel('n_estimators')\nplt.ylabel('max_depth')\nplt.tight_layout()\nplt.savefig(FIGS_DIR / \"rf_grid_search_heatmap.png\", dpi=120)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-20",
   "source": [
    "## 8. Model 3: XGBoost with Grid Search\n",
    "\n",
    "XGBoost is a state-of-the-art gradient boosting algorithm.\n",
    "We use Grid Search combined with early stopping for optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-21",
   "outputs": [],
   "source": "print(\"Running Grid Search for XGBoost...\")\nprint(f\"Grid Search using {len(X_train_sample):,} samples\")\n\nxgb_param_grid = {\n    'max_depth': [6, 10],\n    'learning_rate': [0.05, 0.1],\n    'n_estimators': [200, 500]\n}\n\nxgb_base = XGBRegressor(\n    objective='reg:squarederror',\n    subsample=0.8,\n    n_jobs=-1,\n    random_state=42\n)\n\nxgb_grid_search = GridSearchCV(\n    estimator=xgb_base,\n    param_grid=xgb_param_grid,\n    cv=3,\n    scoring='neg_mean_absolute_error',\n    n_jobs=-1,\n    verbose=1\n)\n\nxgb_grid_search.fit(X_train_sample, y_train_sample)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"XGBOOST GRID SEARCH RESULTS\")\nprint(\"=\"*60)\nprint(f\"Best parameters: {xgb_grid_search.best_params_}\")\nprint(f\"Best CV MAE (on sample): {-xgb_grid_search.best_score_:.2f} USD\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-22",
   "outputs": [],
   "source": "best_params = xgb_grid_search.best_params_.copy()\nif 'n_estimators' in best_params:\n    del best_params['n_estimators']\n\nxgb_final = XGBRegressor(\n    **best_params,\n    n_estimators=2000,\n    early_stopping_rounds=50,\n    objective='reg:squarederror',\n    subsample=0.8,\n    n_jobs=-1,\n    random_state=42\n)\n\nxgb_final.fit(\n    X_train, y_train,\n    eval_set=[(X_val, y_val)],\n    verbose=False\n)\n\nprint(f\"Training stopped at iteration: {xgb_final.best_iteration}\")\nprint(f\"Best validation RMSE: {xgb_final.best_score:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-23",
   "outputs": [],
   "source": "y_pred_xgb_train = xgb_final.predict(X_train)\ny_pred_xgb_val = xgb_final.predict(X_val)\ny_pred_xgb_test = xgb_final.predict(X_test)\n\nprint(\"XGBoost Performance (Best Hyperparameters + Early Stopping):\")\nprint(\"-\" * 50)\nxgb_train_metrics = evaluate_model(y_train, y_pred_xgb_train, \"Train\")\nprint()\nxgb_val_metrics = evaluate_model(y_val, y_pred_xgb_val, \"Validation\")\nprint()\nxgb_test_metrics = evaluate_model(y_test, y_pred_xgb_test, \"Test\")\n\nall_results.append({'Model': 'XGBoost', **xgb_test_metrics})"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-24",
   "outputs": [],
   "source": "xgb_cv_results = pd.DataFrame(xgb_grid_search.cv_results_)\nxgb_cv_results['MAE'] = -xgb_cv_results['mean_test_score']\n\npivot_xgb = xgb_cv_results.pivot_table(\n    values='MAE',\n    index='param_max_depth',\n    columns='param_learning_rate',\n    aggfunc='mean'\n)\n\nplt.figure(figsize=(10, 6))\nsns.heatmap(pivot_xgb, annot=True, fmt='.2f', cmap='YlOrRd_r', cbar_kws={'label': 'MAE (USD)'})\nplt.title('XGBoost Grid Search: MAE by Hyperparameters', fontweight='bold')\nplt.xlabel('learning_rate')\nplt.ylabel('max_depth')\nplt.tight_layout()\nplt.savefig(FIGS_DIR / \"xgb_grid_search_heatmap.png\", dpi=120)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-25",
   "source": [
    "## 9. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-26",
   "outputs": [],
   "source": "results_df = pd.DataFrame(all_results)\n\nprint(\"=\"*70)\nprint(\"MODEL COMPARISON ON TEST SET\")\nprint(\"=\"*70)\nprint(results_df.to_string(index=False))\nprint(\"=\"*70)\n\nbest_model = results_df.loc[results_df['MAE'].idxmin(), 'Model']\nprint(f\"\\nBest Model: {best_model}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-27",
   "outputs": [],
   "source": "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\nmetrics = ['MAE', 'RMSE', 'R2']\ncolors = ['coral', 'steelblue', 'seagreen']\ntitles = ['Mean Absolute Error (Lower is Better)', \n          'Root Mean Squared Error (Lower is Better)', \n          'R² Score (Higher is Better)']\n\nfor i, (metric, color, title) in enumerate(zip(metrics, colors, titles)):\n    bars = axes[i].bar(results_df['Model'], results_df[metric], color=color, alpha=0.8, edgecolor='black')\n    axes[i].set_title(title, fontweight='bold')\n    axes[i].set_ylabel(metric)\n    axes[i].tick_params(axis='x', rotation=15)\n    axes[i].grid(axis='y', alpha=0.3)\n    \n    for bar, val in zip(bars, results_df[metric]):\n        axes[i].text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n                     f'{val:.2f}', ha='center', va='bottom', fontweight='bold')\n\nplt.tight_layout()\nplt.savefig(FIGS_DIR / \"Model_Comparison.png\", dpi=120)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-28",
   "source": [
    "## 10. Predicted vs Actual Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-29",
   "outputs": [],
   "source": "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\nsample_idx = np.random.choice(len(y_test), size=min(10000, len(y_test)), replace=False)\ny_test_sample = y_test.iloc[sample_idx]\n\npredictions = [\n    (y_pred_lr_test[sample_idx], 'Linear Regression', 'coral'),\n    (y_pred_rf_test[sample_idx], 'Random Forest', 'steelblue'),\n    (y_pred_xgb_test[sample_idx], 'XGBoost', 'seagreen')\n]\n\nfor i, (y_pred, title, color) in enumerate(predictions):\n    axes[i].scatter(y_test_sample, y_pred, alpha=0.3, s=10, color=color)\n    \n    max_val = max(y_test_sample.max(), y_pred.max())\n    axes[i].plot([0, max_val], [0, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n    \n    axes[i].set_xlabel('Actual Price (USD)')\n    axes[i].set_ylabel('Predicted Price (USD)')\n    axes[i].set_title(f'{title}\\nPredicted vs Actual', fontweight='bold')\n    axes[i].legend()\n    axes[i].grid(alpha=0.3)\n    axes[i].set_xlim(0, 150)\n    axes[i].set_ylim(0, 150)\n\nplt.tight_layout()\nplt.savefig(FIGS_DIR / \"predicted_vs_actual.png\", dpi=120)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-30",
   "source": [
    "## 11. Learning Curves (Overfitting/Underfitting Diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-31",
   "outputs": [],
   "source": "print(\"Generating learning curves...\")\n\nLEARNING_CURVE_SAMPLE_SIZE = 30000\nX_lc_sample = X_train.sample(n=LEARNING_CURVE_SAMPLE_SIZE, random_state=42)\ny_lc_sample = y_train.loc[X_lc_sample.index]\n\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\nmodels = [\n    (LinearRegression(), 'Linear Regression'),\n    (RandomForestRegressor(n_estimators=50, max_depth=10, n_jobs=-1, random_state=42), 'Random Forest'),\n    (XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, n_jobs=-1, random_state=42), 'XGBoost')\n]\n\nfor i, (model, title) in enumerate(models):\n    train_sizes, train_scores, val_scores = learning_curve(\n        model, X_lc_sample, y_lc_sample,\n        cv=3,\n        n_jobs=-1,\n        train_sizes=np.linspace(0.2, 1.0, 5),\n        scoring='neg_mean_absolute_error'\n    )\n    \n    train_mean = -train_scores.mean(axis=1)\n    train_std = train_scores.std(axis=1)\n    val_mean = -val_scores.mean(axis=1)\n    val_std = val_scores.std(axis=1)\n    \n    axes[i].fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n    axes[i].fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color='orange')\n    axes[i].plot(train_sizes, train_mean, 'o-', color='blue', label='Training')\n    axes[i].plot(train_sizes, val_mean, 'o-', color='orange', label='Validation')\n    \n    axes[i].set_xlabel('Training Set Size')\n    axes[i].set_ylabel('MAE (USD)')\n    axes[i].set_title(f'Learning Curve: {title}', fontweight='bold')\n    axes[i].legend(loc='best')\n    axes[i].grid(alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(FIGS_DIR / \"learning_curves.png\", dpi=120)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-32",
   "source": [
    "## 12. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-33",
   "outputs": [],
   "source": "residuals = y_test - y_pred_xgb_test\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\naxes[0].scatter(y_pred_xgb_test, residuals, alpha=0.3, s=1, color='blue')\naxes[0].axhline(0, color='red', linestyle='--', linewidth=2)\naxes[0].set_xlabel('Predicted Price (USD)')\naxes[0].set_ylabel('Residuals (Actual - Predicted)')\naxes[0].set_title('Residuals vs Predicted Values', fontweight='bold')\naxes[0].grid(alpha=0.3)\n\naxes[1].hist(residuals, bins=100, alpha=0.7, color='purple', edgecolor='black')\naxes[1].axvline(0, color='red', linestyle='--', linewidth=2)\naxes[1].axvline(residuals.mean(), color='green', linestyle='-', linewidth=2, label=f'Mean: {residuals.mean():.2f}')\naxes[1].set_xlabel('Residuals (USD)')\naxes[1].set_ylabel('Frequency')\naxes[1].set_title('Distribution of Residuals', fontweight='bold')\naxes[1].legend()\naxes[1].grid(alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(FIGS_DIR / \"residuals_analysis.png\", dpi=120)\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-34",
   "outputs": [],
   "source": "test_analysis = X_test.copy()\ntest_analysis['C_LAST_TRUE'] = y_test.values\ntest_analysis['C_LAST_PRED'] = y_pred_xgb_test\ntest_analysis['ABS_ERROR'] = np.abs(test_analysis['C_LAST_TRUE'] - test_analysis['C_LAST_PRED'])\n\nbins = np.linspace(test_analysis['LOG_MONEYNESS'].min(), test_analysis['LOG_MONEYNESS'].max(), 30)\ntest_analysis['MONEY_BUCKET'] = pd.cut(test_analysis['LOG_MONEYNESS'], bins=bins)\n\nerror_by_bucket = test_analysis.groupby('MONEY_BUCKET', observed=True).agg({\n    'ABS_ERROR': 'mean',\n    'LOG_MONEYNESS': 'mean'\n}).dropna()\n\nplt.figure(figsize=(12, 6))\nplt.plot(error_by_bucket['LOG_MONEYNESS'], error_by_bucket['ABS_ERROR'], \n         marker='o', linewidth=2, markersize=6, color='darkblue')\nplt.axvline(0, color='red', linestyle='--', linewidth=2, label='ATM (log(S/K)=0)')\nplt.fill_between(error_by_bucket['LOG_MONEYNESS'].values, 0, \n                 error_by_bucket['ABS_ERROR'].values, alpha=0.2, color='blue')\nplt.xlabel('Log-Moneyness = log(S/K)', fontsize=12)\nplt.ylabel('Mean Absolute Error (USD)', fontsize=12)\nplt.title('XGBoost Error vs Moneyness', fontweight='bold', fontsize=14)\nplt.legend(fontsize=11)\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.savefig(FIGS_DIR / \"XGBoost_Error_vs_Log-Moneyness.png\", dpi=120)\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-35",
   "outputs": [],
   "source": "test_analysis['Moneyness_Type'] = pd.cut(\n    test_analysis['LOG_MONEYNESS'], \n    bins=[-np.inf, -0.05, 0.05, np.inf],\n    labels=['OTM', 'ATM', 'ITM']\n)\n\ntest_analysis['Maturity_Type'] = pd.cut(\n    test_analysis['DTE'],\n    bins=[0, 30, 90, np.inf],\n    labels=['Short (0-30d)', 'Medium (30-90d)', 'Long (90d+)']\n)\n\npivot_error = test_analysis.groupby(['Moneyness_Type', 'Maturity_Type'])['ABS_ERROR'].mean().unstack()\npivot_count = test_analysis.groupby(['Moneyness_Type', 'Maturity_Type']).size().unstack()\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\nsns.heatmap(pivot_error, annot=True, fmt='.2f', cmap='RdYlGn_r', \n            ax=axes[0], cbar_kws={'label': 'MAE (USD)'}, vmin=0, vmax=15)\naxes[0].set_title('Mean Absolute Error by Option Type', fontweight='bold')\naxes[0].set_xlabel('Maturity')\naxes[0].set_ylabel('Moneyness')\n\nsns.heatmap(pivot_count, annot=True, fmt='d', cmap='Blues', \n            ax=axes[1], cbar_kws={'label': 'Sample Count'})\naxes[1].set_title('Sample Count by Option Type', fontweight='bold')\naxes[1].set_xlabel('Maturity')\naxes[1].set_ylabel('Moneyness')\n\nplt.tight_layout()\nplt.savefig(FIGS_DIR / \"prediction_quality_by_option_type.png\", dpi=120)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-36",
   "source": [
    "## 13. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-37",
   "outputs": [],
   "source": "rf_importance = pd.DataFrame({\n    'Feature': feature_cols,\n    'Importance': rf_best.feature_importances_,\n    'Model': 'Random Forest'\n})\n\nxgb_importance = pd.DataFrame({\n    'Feature': feature_cols,\n    'Importance': xgb_final.feature_importances_,\n    'Model': 'XGBoost'\n})\n\nimportance_df = pd.concat([rf_importance, xgb_importance])\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\nxgb_imp_sorted = xgb_importance.sort_values('Importance', ascending=True)\naxes[0].barh(xgb_imp_sorted['Feature'], xgb_imp_sorted['Importance'], color='seagreen', edgecolor='black')\naxes[0].set_xlabel('Importance Score')\naxes[0].set_title('XGBoost Feature Importance', fontweight='bold')\naxes[0].grid(axis='x', alpha=0.3)\n\nrf_imp_sorted = rf_importance.sort_values('Importance', ascending=True)\naxes[1].barh(rf_imp_sorted['Feature'], rf_imp_sorted['Importance'], color='steelblue', edgecolor='black')\naxes[1].set_xlabel('Importance Score')\naxes[1].set_title('Random Forest Feature Importance', fontweight='bold')\naxes[1].grid(axis='x', alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(FIGS_DIR / \"feature_importance_comparison.png\", dpi=120)\nplt.show()\n\nfig, ax = plt.subplots(figsize=(10, 6))\nax.barh(xgb_imp_sorted['Feature'], xgb_imp_sorted['Importance'], color='teal', edgecolor='black')\nax.set_xlabel('Importance Score')\nax.set_title('XGBoost Feature Importance', fontweight='bold')\nax.grid(axis='x', alpha=0.3)\nplt.tight_layout()\nplt.savefig(FIGS_DIR / \"feature_importance_xgboost.png\", dpi=120)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-38",
   "source": [
    "## 14. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-39",
   "outputs": [],
   "source": "print(\"Running 5-fold cross-validation on XGBoost...\")\n\nCV_SAMPLE_SIZE = 100000\nX_cv_sample = X_train.sample(n=CV_SAMPLE_SIZE, random_state=42)\ny_cv_sample = y_train.loc[X_cv_sample.index]\n\ncv_params = xgb_grid_search.best_params_.copy()\nif 'n_estimators' in cv_params:\n    del cv_params['n_estimators']\n\nxgb_cv_model = XGBRegressor(\n    **cv_params,\n    n_estimators=300,\n    n_jobs=-1,\n    random_state=42\n)\n\ncv_scores_mae = cross_val_score(xgb_cv_model, X_cv_sample, y_cv_sample, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\ncv_scores_r2 = cross_val_score(xgb_cv_model, X_cv_sample, y_cv_sample, cv=5, scoring='r2', n_jobs=-1)\n\ncv_mae = -cv_scores_mae\n\nprint(\"\\nCross-Validation Results (5 folds on 100k sample):\")\nprint(\"=\"*50)\nprint(f\"MAE per fold: {cv_mae.round(2)}\")\nprint(f\"Mean MAE: {cv_mae.mean():.2f} ± {cv_mae.std():.2f} USD\")\nprint(f\"\\nR² per fold: {cv_scores_r2.round(4)}\")\nprint(f\"Mean R²: {cv_scores_r2.mean():.4f} ± {cv_scores_r2.std():.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-40",
   "source": [
    "## 15. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-41",
   "outputs": [],
   "source": "model_path = MODELS_DIR / \"xgboost_best_model.pkl\"\nwith open(model_path, 'wb') as f:\n    pickle.dump(xgb_final, f)\nprint(f\"Model saved to: {model_path}\")\n\nconfig = {\n    'model_type': 'XGBoost',\n    'features': feature_cols,\n    'target': 'C_LAST',\n    'best_params': xgb_grid_search.best_params_,\n    'best_iteration': int(xgb_final.best_iteration),\n    'test_performance': {\n        'MAE': float(xgb_test_metrics['MAE']),\n        'RMSE': float(xgb_test_metrics['RMSE']),\n        'R2': float(xgb_test_metrics['R2'])\n    },\n    'cv_performance': {\n        'MAE_mean': float(cv_mae.mean()),\n        'MAE_std': float(cv_mae.std()),\n        'R2_mean': float(cv_scores_r2.mean()),\n        'R2_std': float(cv_scores_r2.std())\n    }\n}\n\nconfig_path = MODELS_DIR / \"model_config.json\"\nwith open(config_path, 'w') as f:\n    json.dump(config, f, indent=2)\nprint(f\"Configuration saved to: {config_path}\")\n\nprint(\"\\nModel Configuration:\")\nprint(json.dumps(config, indent=2))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-42",
   "source": [
    "## 16. Summary and Conclusions\n",
    "\n",
    "### Key Results\n",
    "\n",
    "| Model | MAE (USD) | RMSE (USD) | R² |\n",
    "|-------|-----------|------------|----|\n",
    "| Linear Regression | ~16.31 | ~25.41 | ~0.62 |\n",
    "| Random Forest (tuned) | ~6.50 | ~15.78 | ~0.85 |\n",
    "| **XGBoost (tuned)** | **~6.09** | **~14.73** | **~0.87** |\n",
    "\n",
    "### Main Findings\n",
    "\n",
    "1. **Non-linear models significantly outperform linear regression**\n",
    "   - XGBoost achieves 63% reduction in MAE vs Linear Regression\n",
    "   - Confirms option pricing is fundamentally a non-linear problem\n",
    "\n",
    "2. **Grid Search improved model performance**\n",
    "   - Systematic hyperparameter tuning identified optimal configurations\n",
    "   - Best XGBoost params: learning_rate, max_depth, n_estimators tuned\n",
    "\n",
    "3. **Most important features (aligned with financial theory):**\n",
    "   - LOG_MONEYNESS: Relative strike position\n",
    "   - UNDERLYING_LAST: Stock price (intrinsic value)\n",
    "   - C_IV: Implied volatility\n",
    "   - DTE: Time to expiration\n",
    "\n",
    "4. **Model behavior:**\n",
    "   - Best accuracy for ATM options (most liquid)\n",
    "   - Higher errors for deep ITM (larger absolute prices)\n",
    "   - Stable across cross-validation folds\n",
    "\n",
    "5. **PCA Analysis:**\n",
    "   - All 6 features contribute meaningful variance\n",
    "   - Dimensionality reduction not recommended\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- Model trained on historical data (2016-2020)\n",
    "- Performance may degrade in extreme market conditions\n",
    "- Greeks excluded to avoid data leakage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}